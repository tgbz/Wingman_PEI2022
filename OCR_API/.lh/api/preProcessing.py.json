{
    "sourceFile": "api/preProcessing.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 3,
            "patches": [
                {
                    "date": 1669738370825,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1669738380777,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,9 +6,9 @@\n from os import path\r\n from typing import TypeVar, Callable, Sequence\r\n from functools import reduce\r\n import itertools as it\r\n-import jiwer\r\n+#import jiwer\r\n from scipy.ndimage import interpolation as inter\r\n import mediapipe as mp\r\n import rembg \r\n import imutils\r\n"
                },
                {
                    "date": 1669738387256,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,9 +8,9 @@\n from functools import reduce\r\n import itertools as it\r\n #import jiwer\r\n from scipy.ndimage import interpolation as inter\r\n-import mediapipe as mp\r\n+#import mediapipe as mp\r\n import rembg \r\n import imutils\r\n import math\r\n \r\n"
                },
                {
                    "date": 1669738399509,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,9 +9,9 @@\n import itertools as it\r\n #import jiwer\r\n from scipy.ndimage import interpolation as inter\r\n #import mediapipe as mp\r\n-import rembg \r\n+#import rembg \r\n import imutils\r\n import math\r\n \r\n \r\n"
                }
            ],
            "date": 1669738370825,
            "name": "Commit-0",
            "content": "import cv2\r\nimport pytesseract\r\nimport numpy as np\r\nimport argparse    \r\nfrom PIL import Image\r\nfrom os import path\r\nfrom typing import TypeVar, Callable, Sequence\r\nfrom functools import reduce\r\nimport itertools as it\r\nimport jiwer\r\nfrom scipy.ndimage import interpolation as inter\r\nimport mediapipe as mp\r\nimport rembg \r\nimport imutils\r\nimport math\r\n\r\n\r\ndef parse():\r\n    ap = argparse.ArgumentParser()\r\n    ap.add_argument(\"image\",\r\n        help=\"path to input receipt image\")\r\n    ap.add_argument(\"-d\", \"--debug\", default=False, action='store_true',\r\n        help=\"whether or not we are visualizing each step of the pipeline\")\r\n    ap.add_argument(\"-o\", \"--output\", default=False, action='store_true',\r\n        help=\"whether or not results are exported to a txt file\")\r\n    args = vars(ap.parse_args())\r\n\r\n    return args['image'], args['debug'], args['output']\r\n\r\n\r\n\r\nT = TypeVar('T')\r\ndef pipeline(value: T,\r\n            function_pipeline: Sequence[Callable[[T], T]],) -> T:    \r\n    return reduce(lambda v, f: f(v), function_pipeline, value)\r\n\r\n\r\n\r\ndef show(image,window=\"Image\",stop = True):\r\n    cv2.imshow(window, image)\r\n    if stop: cv2.waitKey(0)\r\n    \r\n\r\n\r\n#Normalizes image color\r\ndef normalize(image,debug = False):\r\n    norm = np.zeros((image.shape[0], image.shape[1]))\r\n    final = cv2.normalize(image, norm, 0, 255, cv2.NORM_MINMAX)\r\n\r\n    if debug: show(final,'Normalized')\r\n    return final\r\n\r\n\r\ndef remove_shadows(image,debug = False):\r\n    rgb_planes = cv2.split(image)\r\n\r\n    result_planes = []\r\n    result_norm_planes = []\r\n    for plane in rgb_planes:\r\n        dilated_img = cv2.dilate(plane, np.ones((7,7), np.uint8))\r\n        bg_img = cv2.medianBlur(dilated_img, 21)\r\n        diff_img = 255 - cv2.absdiff(plane, bg_img)\r\n        norm_img = cv2.normalize(diff_img,None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\r\n        result_planes.append(diff_img)\r\n        result_norm_planes.append(norm_img)\r\n\r\n    result = cv2.merge(result_planes)\r\n    return result\r\n\r\ndef crop_rect(img, rect):\r\n    # get the parameter of the small rectangle\r\n    center = rect[0]\r\n    size = rect[1]\r\n    angle = rect[2]\r\n    center, size = tuple(map(int, center)), tuple(map(int, size))\r\n\r\n    # get row and col num in img\r\n    rows, cols = img.shape[0], img.shape[1]\r\n\r\n    M = cv2.getRotationMatrix2D(center, angle, 1)\r\n    img_rot = cv2.warpAffine(img, M, (cols, rows))\r\n    out = cv2.getRectSubPix(img_rot, size, center)\r\n\r\n    return out, img_rot\r\n\r\n\r\ndef dskw(image,coord):\r\n    \r\n    # assume coord is a list with 8 float values, the points of the rectangle area should\r\n    # have be clockwise\r\n\r\n    # cv2.drawContours(img, [cnt], 0, (128, 255, 0), 3)\r\n    # find the rotated rectangle enclosing the contour\r\n    # rect has 3 elments, the first is rectangle center, the second is\r\n    # width and height of the rectangle and the third is the rotation angle\r\n    print(coord)\r\n    rect = cv2.minAreaRect(coord)\r\n    print(\"rect: {}\".format(rect))\r\n    # convert rect to 4 points format\r\n    box = cv2.boxPoints(rect)\r\n    box = np.int0(box)\r\n    print(\"bounding box: {}\".format(box))\r\n\r\n    # draw the roated rectangle box in the image\r\n    cv2.drawContours(image, [box], 0, (0, 0, 255), 2)\r\n    \r\n    # crop the rotated rectangle from the image\r\n    im_crop, img_rot = crop_rect(image, rect)\r\n    # print(\"size of original img: {}\".format(img.shape))\r\n    # print(\"size of rotated img: {}\".format(img_rot.shape))\r\n    # print(\"size of cropped img: {}\".format(im_crop.shape))\r\n    \r\n    cv2.imshow(\"cropped_box\", im_crop)\r\n    cv2.imshow(\"original contour\", image)\r\n    cv2.imshow(\"rotated image\", img_rot)\r\n    \r\n    cv2.waitKey(0)\r\n    return img_rot\r\n\r\n\r\ndef deskew(image,delta=1, limit=5,debug = False):\r\n    def determine_score(arr, angle):\r\n        data = inter.rotate(arr, angle, reshape=False, order=0)\r\n        histogram = np.sum(data, axis=1)\r\n        score = np.sum((histogram[1:] - histogram[:-1]) ** 2)\r\n        return histogram, score\r\n\r\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1] \r\n\r\n    scores = []\r\n    angles = np.arange(-limit, limit + delta, delta)\r\n    for angle in angles:\r\n        histogram, score = determine_score(thresh, angle)\r\n        scores.append(score)\r\n\r\n    best_angle = angles[scores.index(max(scores))]\r\n\r\n    (h, w) = image.shape[:2]\r\n    center = (w // 2, h // 2)\r\n    M = cv2.getRotationMatrix2D(center, best_angle, 1.0)\r\n\r\n    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, \\\r\n              borderMode=cv2.BORDER_REPLICATE)\r\n\r\n    \r\n    if debug: show(rotated,'Deskewd')\r\n    return rotated\r\n    \r\n\r\n\r\n\r\n#Scales the image so it has at least 300 dpi\r\ndef scaling(image,debug = False):\r\n    color_converted = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n    im = Image.fromarray(color_converted)\r\n\r\n    length_x, width_y = im.size\r\n    factor = min(1, float(1024.0 / length_x))\r\n    size = int(factor * length_x), int(factor * width_y)\r\n\r\n    resized = np.array(im.resize(size, Image.Resampling.LANCZOS))\r\n    final = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR) \r\n    if debug: show(final,'scaling')\r\n    return final\r\n\r\n\r\n\r\n#Eliminates noise of a colored image\r\ndef remove_noise_colored(image,debug = False):\r\n    final = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 15)\r\n    if debug: show(final,'noise_colored')\r\n    return final\r\n    \r\n\r\n\r\n#Eliminates noise of a grayscale image\r\ndef remove_noise(image,debug = False):\r\n    final = cv2.fastNlMeansDenoising(image, None, 3, 7, 21)\r\n    if debug: show(final,'noise')\r\n    return final\r\n\r\n\r\n\r\ndef binaryAdaptative(image,debug = False):\r\n    image = remove_noise(image)\r\n    image = grayscale(image)\r\n    final = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\r\n    if debug: show(final,'binaryAdpt')\r\n    return final\r\n\r\n\r\n\r\ndef gaussianBlur(image,debug = False):\r\n    final = cv2.GaussianBlur(image,(5,5),0)\r\n    if debug: show(final,'Gaussian')\r\n    return final\r\n\r\n\r\n\r\n#Turns each pixel into 0 or 1 depending on a threshold using otsus binarization\r\ndef binaryOtsuGauss(image,debug = False):\r\n    _,final = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\r\n    if debug: show(final,'binary')\r\n    return final\r\n\r\n\r\n\r\n#Turns the image to grayscale\r\ndef grayscale(image,debug = False):\r\n    final = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n    if debug: show(final,'grayscale')\r\n    return final\r\n\r\n\r\n\r\n# Automatic brightness and contrast optimization with optional histogram clipping\r\ndef brightness_contrast(image, clip_hist_percent=1,debug = False):\r\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n    \r\n    # Calculate grayscale histogram\r\n    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\r\n    hist_size = len(hist)\r\n    \r\n    # Calculate cumulative distribution from the histogram\r\n    accumulator = []\r\n    accumulator.append(float(hist[0]))\r\n    for index in range(1, hist_size):\r\n        accumulator.append(accumulator[index -1] + float(hist[index]))\r\n    \r\n    # Locate points to clip\r\n    maximum = accumulator[-1]\r\n    clip_hist_percent *= (maximum/100.0)\r\n    clip_hist_percent /= 2.0\r\n    \r\n    # Locate left cut\r\n    minimum_gray = 0\r\n    while accumulator[minimum_gray] < clip_hist_percent:\r\n        minimum_gray += 1\r\n    \r\n    # Locate right cut\r\n    maximum_gray = hist_size -1\r\n    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\r\n        maximum_gray -= 1\r\n    \r\n    # Calculate alpha and beta values\r\n    alpha = 255 / (maximum_gray - minimum_gray)\r\n    beta = -minimum_gray * alpha\r\n\r\n    final = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\r\n    if debug: show(final,'b&c')\r\n    return final\r\n\r\n\r\n\r\n#Removes background of an image\r\ndef remove_bg(image,debug = False):\r\n    change_background_mp = mp.solutions.selfie_segmentation\r\n    change_bg_segment = change_background_mp.SelfieSegmentation(1)\r\n\r\n    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n\r\n    result = change_bg_segment.process(rgb_img)\r\n\r\n    binary_mask = result.segmentation_mask\r\n\r\n    cv2.imshow(\"mask\", binary_mask)\r\n    cv2.imshow(\"image\", image)\r\n    cv2.waitKey()\r\n\r\n    binary_mask_3 = np.dstack((binary_mask,binary_mask,binary_mask))\r\n\r\n    image = np.where(binary_mask_3, image, 255)    \r\n \r\n    if debug: show(image) \r\n    return image\r\n\r\ndef padding(image):\r\n    old_image_height, old_image_width, channels = image.shape\r\n    print(channels)\r\n\r\n    # create new image of desired size and color (blue) for padding\r\n    new_image_width = old_image_width+100\r\n    new_image_height = old_image_height+100\r\n\r\n    color = (0,0,0,0)\r\n    result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\r\n\r\n    # compute center offset\r\n    x_center = (new_image_width - old_image_width) // 2\r\n    y_center = (new_image_height - old_image_height) // 2\r\n\r\n    # copy image image into center of result image\r\n    result[y_center:y_center+old_image_height,x_center:x_center+old_image_width] = image\r\n\r\n    return result\r\n\r\n#Removes background of an image\r\ndef remove_bg2(image,debug = True):\r\n    h,w,c = image.shape\r\n    image = rembg.remove(image)\r\n    image = padding(image)\r\n\r\n    print('1')\r\n    blurred = gaussianBlur(image)\r\n    show(blurred)\r\n    print('2')\r\n    edged = cv2.Canny(blurred, 75, 200)\r\n    show(edged) \r\n    print('3')\r\n    cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\r\n\r\n\r\n\r\n    print('4')\r\n    cnts = imutils.grab_contours(cnts)\r\n    print('5')\r\n    #cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\r\n    print('6')\r\n    '''\r\n\r\n    # initialize a contour that corresponds to the receipt outline\r\n    receiptCnt = None\r\n    # loop over the contours\r\n    for c in cnts:\r\n        # approximate the contour\r\n        peri = cv2.arcLength(c, True)\r\n        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\r\n        # if our approximated contour has four points, then we can\r\n        # assume we have found the outline of the receipt\r\n        if len(approx) == 4:\r\n            receiptCnt = approx\r\n            break\r\n    print('7')\r\n\r\n    output = image.copy()\r\n    cv2.drawContours(output, [receiptCnt], -1, (0, 255, 0), 2)\r\n    \r\n    print('8')\r\n    cv2.imshow(\"Receipt Outline\", output)\r\n    cv2.waitKey(0)\r\n    '''\r\n    \r\n    image = grayscale(image)\r\n    mask = np.zeros_like(image) # Create mask where white is what we want, black otherwise\r\n    cv2.drawContours(mask, cnts, -1, 255, -1) # Draw filled contour in mask\r\n    show(mask) \r\n    out = np.zeros_like(image) # Extract out the object and place into output image\r\n    out[mask == 255] = image[mask == 255]\r\n\r\n    # Now crop\r\n    arr = np.where(mask == 255)\r\n    yArr,xArr=arr\r\n    print(mask)\r\n    print(arr)\r\n    lu = [xArr[0],yArr[0]]\r\n    ru = [xArr[0],yArr[0]]\r\n    ld = [xArr[0],yArr[0]]\r\n    rd = [xArr[0],yArr[0]]\r\n    for i in range(len(xArr)):  \r\n        if math.dist((0,0),(xArr[i],yArr[i])) < math.dist((0,0),(lu[0],lu[1])):\r\n            lu = [xArr[i],yArr[i]]\r\n        if math.dist((0,w),(xArr[i],yArr[i])) < math.dist((0,w),(ru[0],ru[1])):\r\n            ru = [xArr[i],yArr[i]]\r\n        if math.dist((h,0),(xArr[i],yArr[i])) < math.dist((h,0),(ld[0],ld[1])):\r\n            ld = [xArr[i],yArr[i]]\r\n        if math.dist((h,w),(xArr[i],yArr[i])) < math.dist((h,w),(rd[0],rd[1])):\r\n            rd = [xArr[i],yArr[i]]\r\n        \r\n    coords = np.array([[lu],[ru],[ld],[rd]])\r\n\r\n\r\n\r\n\r\n\r\n    '''(topy, topx) = (np.min(y), np.min(x))\r\n    (bottomy, bottomx) = (np.max(y), np.max(x))\r\n    out = out[topy:bottomy+1, topx:bottomx+1]'''\r\n\r\n\r\n    # Show the output image\r\n    cv2.imshow('Output', out)\r\n    cv2.waitKey(0)\r\n    cv2.destroyAllWindows()\r\n    \r\n    image = dskw(image,coords)\r\n\r\n    if debug: show(out,'abcde') \r\n    cv2.imwrite(\"lena_centered.jpg\", out)\r\n    return out\r\n\r\n\r\n\r\ndef gen_name(name):\r\n    file = f'_{name}.txt'\r\n    i = 1\r\n    if path.exists(f'_{name}.txt'):\r\n        while(True):\r\n            file = f'_{name}{i}.txt'\r\n            if not path.exists(file): \r\n                break\r\n            i += 1\r\n    return file\r\n    \r\n\r\n\r\ndef generate_text(name,image,out = False):\r\n    text = pytesseract.image_to_string(image)\r\n    if out:\r\n        with open(gen_name(name.replace('>', '')), \"w\") as f:\r\n            f.write(text)\r\n            f.close()\r\n    return text\r\n\r\n\r\n\r\ndef score(out,file):\r\n    with open(file, \"r\") as f:\r\n        real = f.read()\r\n        f.close()\r\n    #cer = jiwer.cer(real, out)*100\r\n    #wer = jiwer.wer(real, out)*100\r\n    cers = \"0\"\r\n    wers = \"0\"\r\n    print(f'Character error: {cers}%\\nWord error: {wers}%\\n')\r\n    return cer,wer\r\n    \r\n\r\n\r\nif __name__ == \"__main__\":\r\n    \r\n\r\n    filename,debug,output = parse()\r\n\r\n    orig = cv2.imread(filename)\r\n    if debug: show(orig,'Original')\r\n    image = orig.copy()\r\n\r\n    #availableProcesses = [normalize,remove_noise,remove_shadows]\r\n    availableProcesses = [remove_bg2,normalize]\r\n    #availableProcesses = [binaryAdaptative,normalize,grayscale,gaussianBlur,remove_noise,scaling,brightness_contrast]\r\n\r\n    arr = [availableProcesses]\r\n    for L in range(len(availableProcesses) + 1):\r\n        for subset in it.combinations(availableProcesses, L):\r\n            arr.append(subset)\r\n    arr = [[remove_bg2]]\r\n\r\n    results = {}\r\n    #pl = (normalize,scaling,remove_noise_colored,brightness_contrast)\r\n    iter = 1\r\n    for i in arr: \r\n        name = ''\r\n        fst = True\r\n        for f in i:\r\n            if not fst:\r\n                name += '->'\r\n            fst = False\r\n            name += f.__name__ \r\n        if name == '':\r\n            name = 'NoPreprocessing'\r\n        print(f\"Trying {name}\\n({iter}/{len(arr)})\")\r\n        iter += 1\r\n        #try:\r\n        cer,wer = score(generate_text(name,pipeline(image,i),output),'truerec3.txt')\r\n        results[name] = [cer,wer]\r\n        #except:\r\n            #print(f\"Error in {name}\\n\")\r\n            #continue\r\n\r\n\r\n    print(\"Done!\")\r\n    a = sorted(results.items(), key=lambda x: x[1][0])  \r\n\r\n    for ii in a:\r\n        print(ii[0] + '\\ncer: ' + \"{:.2f}\".format(ii[1][0]) + '\\n' + 'wer: ' + \"{:.2f}\".format(ii[1][1]) + '\\n\\n')  \r\n\r\n\r\n\r\n'''remove_noise\r\ncer: 10.94\r\nwer: 48.28\r\n\r\nremove_noise->scaling\r\ncer: 10.94\r\nwer: 48.28\r\n\r\nnormalize->remove_noise\r\ncer: 11.04\r\nwer: 45.69\r\n\r\nnormalize->remove_noise->scaling\r\ncer: 11.04\r\nwer: 45.69\r\n\r\nnormalize->remove_noise->brightness_contrast\r\ncer: 11.35\r\nwer: 48.28\r\n\r\nnormalize->remove_noise->scaling->brightness_contrast\r\ncer: 11.35\r\nwer: 48.28\r\n\r\nnormalize\r\ncer: 11.45\r\nwer: 46.55\r\n\r\nnormalize->scaling\r\ncer: 11.45\r\nwer: 46.55\r\n\r\nnormalize->brightness_contrast\r\ncer: 11.45\r\nwer: 45.69\r\n\r\nnormalize->scaling->brightness_contrast\r\ncer: 11.45\r\nwer: 45.69\r\n\r\nNo Preprocessing\r\ncer: 11.65\r\nwer: 46.55\r\n\r\nscaling\r\ncer: 11.65\r\nwer: 46.55\r\n\r\nbrightness_contrast\r\ncer: 11.96\r\nwer: 50.00\r\n\r\nscaling->brightness_contrast\r\ncer: 11.96\r\nwer: 50.00\r\n\r\nnormalize->gaussianBlur->remove_noise->brightness_contrast\r\ncer: 13.07\r\nwer: 56.03'''"
        }
    ]
}